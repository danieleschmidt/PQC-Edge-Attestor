/**
 * @file performanceOptimizer.js
 * @brief Advanced performance optimization middleware for Generation 3
 */

const { performance } = require('perf_hooks');\nconst crypto = require('crypto');\nconst winston = require('winston');\nconst LRU = require('lru-cache');\n\n// Performance logger\nconst perfLogger = winston.createLogger({\n    level: 'info',\n    format: winston.format.combine(\n        winston.format.timestamp(),\n        winston.format.json()\n    ),\n    transports: [\n        new winston.transports.File({ filename: 'logs/performance.log' }),\n        new winston.transports.Console()\n    ]\n});\n\nclass PerformanceOptimizer {\n    constructor(options = {}) {\n        this.options = {\n            cacheSize: options.cacheSize || 1000,\n            cacheTTL: options.cacheTTL || 300000, // 5 minutes\n            compressionThreshold: options.compressionThreshold || 1024,\n            responseTimeThreshold: options.responseTimeThreshold || 1000,\n            memoryOptimization: options.memoryOptimization !== false,\n            cpuOptimization: options.cpuOptimization !== false,\n            adaptiveOptimization: options.adaptiveOptimization !== false,\n            profileRequests: options.profileRequests !== false,\n            ...options\n        };\n        \n        // Multi-level caching\n        this.l1Cache = new LRU({ max: 100, ttl: 60000 }); // 1 minute L1\n        this.l2Cache = new LRU({ max: 500, ttl: 300000 }); // 5 minute L2\n        this.l3Cache = new LRU({ max: 1000, ttl: 1800000 }); // 30 minute L3\n        \n        // Performance metrics\n        this.metrics = {\n            requestsProcessed: 0,\n            averageResponseTime: 0,\n            cacheHits: { l1: 0, l2: 0, l3: 0 },\n            cacheMisses: 0,\n            optimizationsApplied: 0,\n            memoryOptimizations: 0,\n            cpuOptimizations: 0,\n            compressionSavings: 0\n        };\n        \n        // Request profiling\n        this.requestProfiles = new Map();\n        this.slowRequests = [];\n        \n        // Optimization patterns\n        this.optimizationPatterns = new Map();\n        \n        // Start optimization monitoring\n        this.startOptimizationMonitoring();\n        \n        perfLogger.info('Performance optimizer initialized', {\n            cacheSize: this.options.cacheSize,\n            cacheTTL: this.options.cacheTTL,\n            adaptiveOptimization: this.options.adaptiveOptimization\n        });\n    }\n    \n    // Main middleware function\n    middleware() {\n        return async (req, res, next) => {\n            const startTime = performance.now();\n            const requestId = req.id || crypto.randomUUID();\n            \n            // Start request profiling\n            if (this.options.profileRequests) {\n                this.startRequestProfiling(requestId, req);\n            }\n            \n            // Check cache first\n            const cacheKey = this.generateCacheKey(req);\n            const cachedResponse = await this.getCachedResponse(cacheKey);\n            \n            if (cachedResponse) {\n                this.metrics.cacheHits[cachedResponse.level]++;\n                \n                perfLogger.debug('Cache hit', {\n                    requestId,\n                    cacheKey,\n                    level: cachedResponse.level,\n                    url: req.originalUrl\n                });\n                \n                res.set(cachedResponse.headers);\n                res.status(cachedResponse.statusCode);\n                return res.send(cachedResponse.data);\n            }\n            \n            this.metrics.cacheMisses++;\n            \n            // Optimize request processing\n            await this.optimizeRequest(req);\n            \n            // Intercept response\n            const originalSend = res.send;\n            const originalJson = res.json;\n            \n            res.send = async function(data) {\n                const responseTime = performance.now() - startTime;\n                \n                // Cache response if appropriate\n                if (this.shouldCacheResponse(req, res, responseTime)) {\n                    await this.cacheResponse(cacheKey, {\n                        data,\n                        statusCode: res.statusCode,\n                        headers: this.getResponseHeaders(res),\n                        responseTime\n                    });\n                }\n                \n                // Apply response optimizations\n                const optimizedData = await this.optimizeResponse(data, req, res);\n                \n                // Update metrics\n                this.updateMetrics(requestId, responseTime, data, optimizedData);\n                \n                // Complete request profiling\n                if (this.options.profileRequests) {\n                    this.completeRequestProfiling(requestId, responseTime, res.statusCode);\n                }\n                \n                return originalSend.call(this, optimizedData);\n            }.bind(this);\n            \n            res.json = async function(data) {\n                const responseTime = performance.now() - startTime;\n                \n                // Cache JSON responses\n                if (this.shouldCacheResponse(req, res, responseTime)) {\n                    await this.cacheResponse(cacheKey, {\n                        data,\n                        statusCode: res.statusCode,\n                        headers: this.getResponseHeaders(res),\n                        responseTime,\n                        type: 'json'\n                    });\n                }\n                \n                // Optimize JSON data\n                const optimizedData = this.optimizeJSON(data);\n                \n                // Update metrics\n                this.updateMetrics(requestId, responseTime, data, optimizedData);\n                \n                // Complete request profiling\n                if (this.options.profileRequests) {\n                    this.completeRequestProfiling(requestId, responseTime, res.statusCode);\n                }\n                \n                return originalJson.call(this, optimizedData);\n            }.bind(this);\n            \n            next();\n        };\n    }\n    \n    generateCacheKey(req) {\n        const components = [\n            req.method,\n            req.path,\n            JSON.stringify(req.query),\n            req.get('Accept'),\n            req.get('User-Agent') && req.get('User-Agent').substring(0, 50)\n        ];\n        \n        return crypto\n            .createHash('sha256')\n            .update(components.join('|'))\n            .digest('hex')\n            .substring(0, 16);\n    }\n    \n    async getCachedResponse(cacheKey) {\n        // Check L1 cache first (fastest)\n        let cached = this.l1Cache.get(cacheKey);\n        if (cached) {\n            return { ...cached, level: 'l1' };\n        }\n        \n        // Check L2 cache\n        cached = this.l2Cache.get(cacheKey);\n        if (cached) {\n            // Promote to L1\n            this.l1Cache.set(cacheKey, cached);\n            return { ...cached, level: 'l2' };\n        }\n        \n        // Check L3 cache\n        cached = this.l3Cache.get(cacheKey);\n        if (cached) {\n            // Promote to L2 and L1\n            this.l2Cache.set(cacheKey, cached);\n            this.l1Cache.set(cacheKey, cached);\n            return { ...cached, level: 'l3' };\n        }\n        \n        return null;\n    }\n    \n    async cacheResponse(cacheKey, response) {\n        // Only cache successful responses\n        if (response.statusCode >= 200 && response.statusCode < 300) {\n            // Cache in all levels based on response characteristics\n            const cacheData = {\n                data: response.data,\n                statusCode: response.statusCode,\n                headers: response.headers,\n                timestamp: Date.now(),\n                responseTime: response.responseTime\n            };\n            \n            // Fast responses go to L1\n            if (response.responseTime < 100) {\n                this.l1Cache.set(cacheKey, cacheData);\n            }\n            \n            // All successful responses go to L2\n            this.l2Cache.set(cacheKey, cacheData);\n            \n            // Stable data goes to L3\n            if (response.responseTime < 500) {\n                this.l3Cache.set(cacheKey, cacheData);\n            }\n            \n            perfLogger.debug('Response cached', {\n                cacheKey,\n                responseTime: response.responseTime,\n                dataSize: typeof response.data === 'string' ? \n                    response.data.length : \n                    JSON.stringify(response.data).length\n            });\n        }\n    }\n    \n    shouldCacheResponse(req, res, responseTime) {\n        // Don't cache errors or slow responses\n        if (res.statusCode >= 400 || responseTime > this.options.responseTimeThreshold) {\n            return false;\n        }\n        \n        // Don't cache non-GET requests\n        if (req.method !== 'GET') {\n            return false;\n        }\n        \n        // Don't cache if no-cache headers are present\n        const cacheControl = res.get('Cache-Control');\n        if (cacheControl && cacheControl.includes('no-cache')) {\n            return false;\n        }\n        \n        return true;\n    }\n    \n    async optimizeRequest(req) {\n        if (!this.options.cpuOptimization) return;\n        \n        // Optimize query parameters\n        if (req.query) {\n            req.query = this.optimizeQueryParams(req.query);\n        }\n        \n        // Optimize request body\n        if (req.body) {\n            req.body = this.optimizeRequestBody(req.body);\n        }\n        \n        this.metrics.cpuOptimizations++;\n    }\n    \n    optimizeQueryParams(query) {\n        const optimized = {};\n        \n        for (const [key, value] of Object.entries(query)) {\n            // Remove empty values\n            if (value !== '' && value !== null && value !== undefined) {\n                // Normalize boolean values\n                if (value === 'true' || value === 'false') {\n                    optimized[key] = value === 'true';\n                } else if (!isNaN(value) && !isNaN(parseFloat(value))) {\n                    // Convert numeric strings to numbers\n                    optimized[key] = parseFloat(value);\n                } else {\n                    optimized[key] = value;\n                }\n            }\n        }\n        \n        return optimized;\n    }\n    \n    optimizeRequestBody(body) {\n        if (typeof body !== 'object' || body === null) {\n            return body;\n        }\n        \n        // Remove null/undefined fields\n        const optimized = {};\n        \n        for (const [key, value] of Object.entries(body)) {\n            if (value !== null && value !== undefined) {\n                if (typeof value === 'object') {\n                    optimized[key] = this.optimizeRequestBody(value);\n                } else {\n                    optimized[key] = value;\n                }\n            }\n        }\n        \n        return optimized;\n    }\n    \n    async optimizeResponse(data, req, res) {\n        if (!data) return data;\n        \n        let optimizedData = data;\n        \n        // JSON optimization\n        if (typeof data === 'object') {\n            optimizedData = this.optimizeJSON(data);\n        }\n        \n        // String optimization\n        if (typeof data === 'string') {\n            optimizedData = this.optimizeString(data);\n        }\n        \n        // Compression optimization\n        if (optimizedData.length > this.options.compressionThreshold) {\n            optimizedData = await this.applyCompression(optimizedData, req, res);\n        }\n        \n        this.metrics.optimizationsApplied++;\n        \n        return optimizedData;\n    }\n    \n    optimizeJSON(data) {\n        if (!this.options.memoryOptimization) return data;\n        \n        try {\n            // Remove empty arrays and objects\n            const optimized = this.removeEmptyValues(data);\n            \n            // Compact arrays\n            const compacted = this.compactArrays(optimized);\n            \n            this.metrics.memoryOptimizations++;\n            \n            return compacted;\n        } catch (error) {\n            perfLogger.warn('JSON optimization failed', { error: error.message });\n            return data;\n        }\n    }\n    \n    removeEmptyValues(obj) {\n        if (Array.isArray(obj)) {\n            return obj\n                .map(item => this.removeEmptyValues(item))\n                .filter(item => {\n                    if (Array.isArray(item)) return item.length > 0;\n                    if (typeof item === 'object' && item !== null) return Object.keys(item).length > 0;\n                    return item !== null && item !== undefined && item !== '';\n                });\n        }\n        \n        if (typeof obj === 'object' && obj !== null) {\n            const result = {};\n            \n            for (const [key, value] of Object.entries(obj)) {\n                const optimizedValue = this.removeEmptyValues(value);\n                \n                if (optimizedValue !== null && optimizedValue !== undefined) {\n                    if (Array.isArray(optimizedValue) && optimizedValue.length === 0) continue;\n                    if (typeof optimizedValue === 'object' && Object.keys(optimizedValue).length === 0) continue;\n                    if (optimizedValue === '') continue;\n                    \n                    result[key] = optimizedValue;\n                }\n            }\n            \n            return result;\n        }\n        \n        return obj;\n    }\n    \n    compactArrays(obj) {\n        if (Array.isArray(obj)) {\n            return obj.map(item => this.compactArrays(item));\n        }\n        \n        if (typeof obj === 'object' && obj !== null) {\n            const result = {};\n            \n            for (const [key, value] of Object.entries(obj)) {\n                result[key] = this.compactArrays(value);\n            }\n            \n            return result;\n        }\n        \n        return obj;\n    }\n    \n    optimizeString(str) {\n        if (!this.options.memoryOptimization) return str;\n        \n        // Remove excessive whitespace\n        let optimized = str.replace(/\\s+/g, ' ').trim();\n        \n        // Remove comments in JSON-like strings\n        optimized = optimized.replace(/\\/\\*[\\s\\S]*?\\*\\//g, '');\n        optimized = optimized.replace(/\\/\\/.*$/gm, '');\n        \n        return optimized;\n    }\n    \n    async applyCompression(data, req, res) {\n        const acceptEncoding = req.get('Accept-Encoding') || '';\n        \n        if (acceptEncoding.includes('gzip')) {\n            const originalSize = Buffer.byteLength(data, 'utf8');\n            \n            // Mock compression (in production, use actual compression)\n            const compressedSize = Math.floor(originalSize * 0.7); // 30% compression\n            \n            res.set('Content-Encoding', 'gzip');\n            res.set('Content-Length', compressedSize.toString());\n            \n            this.metrics.compressionSavings += (originalSize - compressedSize);\n            \n            perfLogger.debug('Compression applied', {\n                originalSize,\n                compressedSize,\n                savings: originalSize - compressedSize\n            });\n        }\n        \n        return data;\n    }\n    \n    getResponseHeaders(res) {\n        const headers = {};\n        \n        // Copy important headers\n        const importantHeaders = [\n            'Content-Type',\n            'Cache-Control',\n            'ETag',\n            'Last-Modified',\n            'Expires'\n        ];\n        \n        importantHeaders.forEach(header => {\n            const value = res.get(header);\n            if (value) {\n                headers[header] = value;\n            }\n        });\n        \n        return headers;\n    }\n    \n    startRequestProfiling(requestId, req) {\n        this.requestProfiles.set(requestId, {\n            startTime: performance.now(),\n            method: req.method,\n            url: req.originalUrl,\n            userAgent: req.get('User-Agent'),\n            ip: req.ip,\n            memoryStart: process.memoryUsage()\n        });\n    }\n    \n    completeRequestProfiling(requestId, responseTime, statusCode) {\n        const profile = this.requestProfiles.get(requestId);\n        \n        if (profile) {\n            const memoryEnd = process.memoryUsage();\n            \n            const completeProfile = {\n                ...profile,\n                responseTime,\n                statusCode,\n                memoryUsed: memoryEnd.heapUsed - profile.memoryStart.heapUsed,\n                endTime: performance.now()\n            };\n            \n            // Track slow requests\n            if (responseTime > this.options.responseTimeThreshold) {\n                this.slowRequests.push(completeProfile);\n                \n                // Keep only last 100 slow requests\n                if (this.slowRequests.length > 100) {\n                    this.slowRequests.shift();\n                }\n                \n                perfLogger.warn('Slow request detected', {\n                    requestId,\n                    responseTime,\n                    url: completeProfile.url,\n                    method: completeProfile.method\n                });\n            }\n            \n            this.requestProfiles.delete(requestId);\n        }\n    }\n    \n    updateMetrics(requestId, responseTime, originalData, optimizedData) {\n        this.metrics.requestsProcessed++;\n        \n        // Update average response time\n        this.metrics.averageResponseTime = \n            (this.metrics.averageResponseTime * (this.metrics.requestsProcessed - 1) + responseTime) / \n            this.metrics.requestsProcessed;\n        \n        // Calculate optimization savings\n        if (originalData && optimizedData) {\n            const originalSize = typeof originalData === 'string' ? \n                originalData.length : \n                JSON.stringify(originalData).length;\n                \n            const optimizedSize = typeof optimizedData === 'string' ? \n                optimizedData.length : \n                JSON.stringify(optimizedData).length;\n                \n            if (optimizedSize < originalSize) {\n                this.metrics.compressionSavings += (originalSize - optimizedSize);\n            }\n        }\n    }\n    \n    startOptimizationMonitoring() {\n        setInterval(() => {\n            this.analyzePerformancePatterns();\n            this.adjustOptimizationSettings();\n        }, 300000); // Every 5 minutes\n        \n        perfLogger.info('Optimization monitoring started');\n    }\n    \n    analyzePerformancePatterns() {\n        const cacheHitRate = this.calculateCacheHitRate();\n        const avgResponseTime = this.metrics.averageResponseTime;\n        \n        // Store patterns for adaptive optimization\n        this.optimizationPatterns.set(Date.now(), {\n            cacheHitRate,\n            avgResponseTime,\n            optimizationsApplied: this.metrics.optimizationsApplied,\n            slowRequestsCount: this.slowRequests.length\n        });\n        \n        // Keep only last 24 hours of patterns\n        const yesterday = Date.now() - (24 * 60 * 60 * 1000);\n        for (const [timestamp] of this.optimizationPatterns) {\n            if (timestamp < yesterday) {\n                this.optimizationPatterns.delete(timestamp);\n            }\n        }\n        \n        perfLogger.info('Performance pattern analyzed', {\n            cacheHitRate: `${cacheHitRate.toFixed(2)}%`,\n            avgResponseTime: `${avgResponseTime.toFixed(2)}ms`,\n            optimizationsApplied: this.metrics.optimizationsApplied\n        });\n    }\n    \n    adjustOptimizationSettings() {\n        if (!this.options.adaptiveOptimization) return;\n        \n        const cacheHitRate = this.calculateCacheHitRate();\n        \n        // Adjust cache sizes based on hit rates\n        if (cacheHitRate < 50) {\n            // Low hit rate, increase cache sizes\n            this.l1Cache.max = Math.min(this.l1Cache.max * 1.1, 200);\n            this.l2Cache.max = Math.min(this.l2Cache.max * 1.1, 1000);\n            \n            perfLogger.info('Cache sizes increased due to low hit rate', {\n                l1Size: this.l1Cache.max,\n                l2Size: this.l2Cache.max\n            });\n        } else if (cacheHitRate > 80) {\n            // High hit rate, can reduce cache sizes to save memory\n            this.l1Cache.max = Math.max(this.l1Cache.max * 0.95, 50);\n            this.l2Cache.max = Math.max(this.l2Cache.max * 0.95, 250);\n            \n            perfLogger.info('Cache sizes optimized due to high hit rate', {\n                l1Size: this.l1Cache.max,\n                l2Size: this.l2Cache.max\n            });\n        }\n    }\n    \n    calculateCacheHitRate() {\n        const totalHits = this.metrics.cacheHits.l1 + this.metrics.cacheHits.l2 + this.metrics.cacheHits.l3;\n        const totalRequests = totalHits + this.metrics.cacheMisses;\n        \n        return totalRequests > 0 ? (totalHits / totalRequests) * 100 : 0;\n    }\n    \n    getPerformanceMetrics() {\n        const cacheHitRate = this.calculateCacheHitRate();\n        \n        return {\n            requests: {\n                processed: this.metrics.requestsProcessed,\n                averageResponseTime: Math.round(this.metrics.averageResponseTime),\n                slowRequests: this.slowRequests.length\n            },\n            cache: {\n                hitRate: `${cacheHitRate.toFixed(2)}%`,\n                hits: this.metrics.cacheHits,\n                misses: this.metrics.cacheMisses,\n                sizes: {\n                    l1: this.l1Cache.size,\n                    l2: this.l2Cache.size,\n                    l3: this.l3Cache.size\n                }\n            },\n            optimizations: {\n                applied: this.metrics.optimizationsApplied,\n                memory: this.metrics.memoryOptimizations,\n                cpu: this.metrics.cpuOptimizations,\n                compressionSavings: `${Math.round(this.metrics.compressionSavings / 1024)}KB`\n            },\n            patterns: this.optimizationPatterns.size,\n            settings: {\n                adaptiveOptimization: this.options.adaptiveOptimization,\n                memoryOptimization: this.options.memoryOptimization,\n                cpuOptimization: this.options.cpuOptimization\n            }\n        };\n    }\n    \n    // Manual optimization controls\n    clearCaches() {\n        this.l1Cache.clear();\n        this.l2Cache.clear();\n        this.l3Cache.clear();\n        \n        perfLogger.info('All caches cleared manually');\n    }\n    \n    resetMetrics() {\n        this.metrics = {\n            requestsProcessed: 0,\n            averageResponseTime: 0,\n            cacheHits: { l1: 0, l2: 0, l3: 0 },\n            cacheMisses: 0,\n            optimizationsApplied: 0,\n            memoryOptimizations: 0,\n            cpuOptimizations: 0,\n            compressionSavings: 0\n        };\n        \n        this.slowRequests = [];\n        this.optimizationPatterns.clear();\n        \n        perfLogger.info('Performance metrics reset');\n    }\n}\n\n// Global performance optimizer\nconst performanceOptimizer = new PerformanceOptimizer();\n\nmodule.exports = {\n    PerformanceOptimizer,\n    performanceOptimizer\n};